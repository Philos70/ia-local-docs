Local Artificial Intelligence Environment
Username: Pablo
Operating System: Windows 11 Pro
Environment Location: C:\Projects\MCP
Configuration Date: July 2025
‚öôÔ∏è Installed Components
Tool Role in Workflow
LM Studio Local execution of LLM language models
Node.js JavaScript execution engine for orchestration and backend services
GitHub MCP Server Local interface with GitHub via API, Docker container based on Go
Sequential Thinking MCP MCP module for sequential reasoning
Fetch MCP Retrieval of external data to enrich model inputs
Anything LLM LLM model integration and extension platform
üîß GitHub MCP Installation
Project Source: GitHub
Initial File: github-mcp-server-main.zip
Base Language: Go (Golang)
Execution Method: Docker
Steps Completed:
1. Unzip the project to C:\Projects\MCP
2. Validate Dockerfile, go.mod, and main.go files
3. Generate a personal access token on GitHub (classic tokens)
4. Run the Docker container:
docker run -e GITHUB_PERSONAL_ACCESS_TOKEN=your_token -p 8080:8080 mcp-server
üß≠ General Workflow
[LM Studio] ‚Üí [Sequential Thinking MCP] ‚Üì [GitHub MCP + Fetch MCP] ‚Üì [Node.js] ‚Üì [Anything LLM]
Each component fulfills a specific function:
‚Ä¢ Local natural language processing
‚Ä¢ Step-by-step modular reasoning
‚Ä¢ Data retrieval from GitHub and external sources
‚Ä¢ Coordination from Node.js
‚Ä¢ Visualization and expansion via Anything LLM
Enviar comentarios
Paneles laterales
Historial
Guardado
